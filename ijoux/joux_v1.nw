\documentclass{book}

\usepackage{geometry}
\usepackage{noweb}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{parskip}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{patterns}

\newcommand{\join}{\bowtie}
\newcommand{\OMP}{\textsf{OpenMP}\xspace}

\begin{document}

\setcounter{chapter}{2}
\chapter{The Iterated Joux Algorithm}


This file describes an implementation of the iterated Joux algorithm.  
The main function described in this file ``solves'' a (fine) task. 

<<*>>=
#define _XOPEN_SOURCE   /* rand48(...) */
#include <math.h>
#include <stdlib.h>
#include <stdio.h>
#include <assert.h>
#include <err.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <omp.h>

#include "common.h"
#include "linalg.h"
#include "../quadratic/datastructures.h"

<<Type definitions>>
<<Forward declarations>>
<<Auxiliary functions>>
<<The main function>>

@ \section{Processing Tasks}

The technical part consists in computing $AM \join_\ell BM$. All the code is organized
around this difficulty.

We use a \emph{partitioning} (hash) join. To compute $A \join B$, we divide 
$A$ and $B$ into partitions $(A_i)$ and $(B_j)$ such that
$A_i \join B_j = \emptyset$ when $i \neq j$. Radix partitioning puts in $A_i$
all entries from $A$ that begin with $i$ (the $\ell$ most-significant bits
of each key in $A_i$ is $i$). If we divide $A$ using $\ell$ key bits, we end up
with $2^p$ partitions. The first partitionning step must be multi-threaded.
Then all sub-joins can be processed in parallel, each inside a single thread.

The usual way to do radix-partitioning does two passes over the input: a first
pass counts the number of elements in each output bucket, then a second pass
actually dispatches the data.

We choose to do away with the first pass at the expense of a small increase in
storage. Each one of the $T$ threads directly dispatches its slice of the input
into $2^p$ \emph{thread-private} buckets. Each partition $A_i$ is then
composed of $T$ such thread-buckets. An added bonus is that it allows us to do
the matrix multiplication on the fly (during the partitioning step).

The drawback of this approach is that the size of each thread-bucket is not
known in advance. Because the keys are random, we may safely overestimate it
though. If $N$ denotes the size of the input list, then each output bucket 
receives on average $\mu = N / (2^p T)$ entries. A Chernoff bound tells 
us that if $X$ denotes an actual thread-bucket size,
\[
\mathbb{P}\left[X > (1 + \delta)\mu \right] < \left( \frac{e^\delta}{(1+\delta)^{1+\delta}}\right)^\mu.
\]

We want to choose a safety margin $\delta$ such that the possibility of overflow
is remote (say $2^{-100}$). It is then enough to choose
$\delta \gets \sqrt{210 / \mu}$ (this is a loose bound). As long as $N$ is 
large enough, a small $\delta$ (20\% or less) is sufficient, and the space 
overhead is limited. 

When allocating the memory, we enforce alignement on a 64-byte boundary 
(the size of a cache line on most CPUs). In addition, this allows aligned 
access for all possible sizes, including 256-bit registers.

<<Auxiliary functions>>=
static const u32 CACHE_LINE_SIZE = 64;
u64 ROUND(u64 s)
{
	return CACHE_LINE_SIZE * ceil(((double) s) / CACHE_LINE_SIZE);
}

u64 chernoff_bound(u64 N, u32 n_buckets)
{
	double mu = ((double) N) / n_buckets;
	double delta = sqrt(210 / mu);
	return ROUND(N * (1 + delta) / n_buckets);
}


@ Given an input array [[IN]] of size [[N]], we will therefore allocate an array 
[[OUT]] of size $O \gets \left\lceil(1 + \delta)N\right\rceil$. This output 
array is split into $2^p$ ``prefix-zones'' of size $[[psize]] = [[output_size]] / 2^p$.
Each prefix-zone is itself split into $T$ ``thread-zone'' of size
$[[tsize]] = [[psize]] / T$. Each thread writes the entries it reads from the
input into his own thread-zones in all prefix-zones. We ensure that the
``thread-zones'' have a size which is a multiple of  [[CACHE_LINE_SIZE]]. This
large memory allocation can be done once and for all during the processing of
a task.

Another drawback is that when partitioning is over, the data inside each 
``prefix zone'' are not contiguous.

@ \begin{tikzpicture}[>=latex]
  \draw[thick,dotted] (0, 0) -- (0, -1);
  \draw[thick,dotted] (3, 0) -- (3, -1);
  \draw[thick] (0, 0) -- (0, 8);
  \draw[thick] (3, 0) -- (3, 8);
  \draw[thick] (0, 8) -- (3, 8);
  \draw (0, 6) -- +(3, 0);
  \draw (0, 4) -- +(3, 0);
  \draw (0, 2) -- +(3, 0);
  \draw (0, 0) -- +(3, 0);
  \path (0, 8) rectangle node {Thread 0} +(3, -2);
  \path (0, 6) rectangle node {Thread 1} +(3, -2);
  \path (0, 4) rectangle node {Thread 2} +(3, -2);
  \path (0, 2) rectangle node {Thread 3} +(3, -2);

  \newlength{\espacehoriz}
  \setlength{\espacehoriz}{8cm}
  
  \begin{scope}[xshift=\espacehoriz,font=\footnotesize]
    \draw[thick,dotted] (0, 0) -- (0, -1);
    \draw[thick,dotted] (3, 0) -- (3, -1);
    \draw[thick] (0, 0) -- (0, 8);
    \draw[thick] (3, 0) -- (3, 8);
    \draw[thick] (0, 8) -- (3, 8);
    
    \draw[ultra thick] (0, 4) -- +(3, 0);
    \draw[ultra thick] (0, 0) -- +(3, 0);

    \foreach \i/\j in {8cm/0.65, 7cm/0.7, 6cm/0.6, 5cm/0.2, 4cm/0.9, 3cm/0.5, 2cm/0.2, 1cm/0.7}
    	\draw[pattern=north east lines] (0, \i-1cm) rectangle (3, \i-\j*1cm);

    \draw[<->] (4.5, 8) -- node[above, sloped] {[[psize]]} +(0, -4);
    \draw[<->] (4.5, 4) -- node[above, sloped] {[[psize]]} +(0, -4);
    \foreach \i in {0, ..., 7} {
    	\draw[<->] (3.75, \i + 1) -- node[above, sloped] {[[tsize]]} +(0, -1);
    	\draw[thick] (0, \i) -- +(3, 0);
    }
  \end{scope}

  \begin{scope}[shorten >=1mm]
    \draw[->] (3, 7) -- (\espacehoriz, 8 - 0.65 / 2);
    \draw[->] (3, 5) -- (\espacehoriz, 7 - 0.7 / 2);
    \draw[->] (3, 3) -- (\espacehoriz, 6 - 0.6 / 2);
    \draw[->] (3, 1) -- (\espacehoriz, 5 - 0.2 / 2);
    %
    \draw[->] (3, 7) -- (\espacehoriz, 4 - 0.9 / 2);
    \draw[->] (3, 5) -- (\espacehoriz, 3 - 0.5 / 2);
    \draw[->] (3, 3) -- (\espacehoriz, 2 - 0.2 / 2);
    \draw[->] (3, 1) -- (\espacehoriz, 1 - 0.7 / 2);
  \end{scope}
\end{tikzpicture}

The right value of $p$ must be found by trial-and-error. If $p$ is too high, 
partitioning will be slow. If $p$ is too low, the partitions will be too large to 
fit in any cache and doing the sub-joins will be harder. As such, we rely on the
user to provide its value.

We use a global array ([[count]]) to maintain de state of all the 
thread-buckets. Once partitioning is done, the items read by thread $t$ and
sent to the $i$-th partition are in [[scratch]] between index 
[[t * tsize + i * psize]] (inclusive) and [[count[t * fan_out + i]]] 
(exclusive). The rationale is that the [[count]]s used by each thread during
dispatching are contiguous in memory.

Once the partioning is done, we now have to join much smaller sub-slices of 
the input lists. For now, we are going to be naive: we will copy the scattered
data to a single location and do a direct sort-join, just like the v0. Our 
scratch space has to include space for the copied data. We again over-allocate
space using a chernoff bound.

<<The main function>>=
struct task_result_t * iterated_joux_task(const char *hash_dir, struct jtask_id_t *task, u32 p)
{
	static const bool verbose = true;
	struct task_result_t *result = result_init();
	double start = wtime();
	if (verbose)
		printf("Loading...\n");
	<<Load data from disk; set [[L], [[n]]>>
	if (verbose)
		printf("Permuting...\n");
	<<Randomly permute $A$ and $B$>>
	<<Prepare task-global variables>>
	if (verbose) {
		<<Display task info>>
	}
	for (u32 u = 0; u < n_blocks; u++)
		process_block_v1(&self, u, true);
	<<Release memory>>
	if (verbose) {
		<<Display task timing>>
	}
	return result;
}

@ Because of our preprocessing, the hash files are sorted. The input lists are
thus highly non-random. In order to be able to rely on the randomness of the
inputs, we re-randomize them by randomly permuting $A$ and $B$.

<<Randomly permute $A$ and $B$>>=
for (u32 k = 0; k < 2; k++)
	for (u32 i = 0; i < n[k] - 1; i++) {
		u32 j = i + (lrand48() % (n[k] - i));
		u64 x = L[k][i];
		L[k][i] = L[k][j];
		L[k][j] = x;
	}


@ If requested, we are capable of displaying some information.

<<Display task info>>=
	/* task-level */
printf("Task: |A|=%d,  |B|=%d,  |C|=%d\n", n[0], n[1], n[2]);
double mbytes = 8. * (n[0] + n[1] + n[2]) / 1048576.0;
printf("Task volume : %.1fMbyte of hashes\n", mbytes);
double logsols = log2(n[0]) + log2(n[1]) + log2(n[2]);
printf("Est. #solutions : %g\n", pow(2, logsols - 64));
	/* block-level */
printf("Using l = %d (if no rank deffect)\n", self.l);
printf("#blocks = %d\n", n_blocks);


<<Display task timing>>=
double task_duration = wtime() - start;
u32 n_coarse_tasks = 1 << (2 * task->k);
double total = task_duration * n_coarse_tasks * task->k2;
printf("Task duration: %.1f s\n", task_duration);
printf("Est. total time: %.3e h\n", total / 3600);


@ \section{Task-wide Preparations}

\subsection{Data Loading}

Preparations include loading the data from disk. We expected a fair amount of 
data (say, 4Gb). Therefore this may take some time. In the future, we would
use this time to do something useful (try to precompute some matrices ?).

<<Load data from disk; set [[L], [[n]]>>=
u64 *L[3];
u32 n[3];
for (u32 k = 0; k < 3; k++) {	
	<<Determine [[filename]] and Query file size>>
	<<Allocate memory>>
	<<Open file and load hashes>>
}

@ The following code is NOT DRY wrt quadratic. If we are dealing with $C$, we
ajust the offset and size (as given by the task descriptor).

<<Determine [[filename]] and Query file size>>=
char filename[255];
char *kind_name[3] = {"foo", "bar", "foobar"};
sprintf(filename, "%s/%s.%03x", hash_dir, kind_name[k], task->idx[k]);
struct stat infos;
if (stat(filename, &infos))
	err(1, "fstat failed on %s", filename);
assert((infos.st_size % 8) == 0);
u64 m = infos.st_size / sizeof(u64) / task->k2;
u64 lo = 0;
u64 hi = infos.st_size;
u32 r = task->r;
if (k == 2) {
	lo = 8 * (r * m);
	hi = MIN(hi, 8 * ((r  + 1) * m));
}
assert (lo != hi);


@ We use [[aligned_alloc]] (available in \textsf{C11}) to allocate aligned 
memory.

<<Allocate memory>>=
u64 aligned_size = ROUND(hi - lo);
L[k] = aligned_alloc(64, aligned_size);
if (L[k] == NULL)
	err(1, "failed to allocate memory");
n[k] = (hi - lo) / sizeof(u64);


<<Open file and load hashes>>=
FILE *f = fopen(filename, "r");
if (f == NULL)
	err(1, "fopen failed (%s)", filename);
fseek(f, lo, SEEK_SET);
u64 check = fread(L[k], 1, hi - lo, f);
if ((check != hi - lo) || ferror(f))
	err(1, "fread : read %" PRId64 ", expected %zd", check, hi - lo);
if (fclose(f))
	err(1, "fclose %s", filename);

<<Release memory>>=
for (u32 k = 0;  k < 3; k++)
	free(L[k]);


@ \subsection{Other Preparations (Scratch space, etc.)}

There are a few knobs that we have to set up before processing blocks. One of
these is the join width $\ell$. The task is split into blocks by splitting the
$C$  list into very small slices of size $64 - \ell$. The optimal value of
$\ell$ is $\max (\log_2 A, \log_2 B)$.


<<Prepare task-global variables>>=
u32 l = ceil(MAX(log2(n[0]), log2(n[1])));
u32 n_blocks = ceil(n[2] / (64. - l));

@ We must allocate all the scratch space needed for the multi-threaded
partitioning step and the subsequent parallel sub-joins.

<<Type definitions>>=
struct side_t {
	u64 *L;               /* input list */
	u32 n;                /* size of L */
	
	/**** multi-threaded partitioning ****/
	u32 psize;            /* capacity of partitions */
	u32 tsize;            /* capacity of thread-private buckets */
	u64 *scratch;         /* scratch space for partitioning */
	u32 *count;           /* counters for dispatching */
	
	/**** parallel sub-joins ****/
	u64 *partition;       /* thread-private scratch space for sub-joins */
	u32 partition_size;
};

struct context_t {
	/**** ``raw'' input data ****/
	u64 *L[3];
	u32 n[3];
	
	/**** tuning parameters ****/
	u32 T;         /* number of threads */
	u32 l;         /* join width in bits */
	u32 p;         /* fan-out of the first partitioning step */

	/**** conveniently presented input data and scratch space ****/
	struct side_t side[2];
	
	/**** output ****/
	struct task_result_t *result;
};


@ As discussed in the introduction, we need some scratch space to hold the 
partition data structure for both $A$ and $B$. The [[struct side_t]] object
is made for this.

<<Auxiliary functions>>=
void prepare_side(struct context_t *self, u32 k)
{
	u32 T = self->T;
	u32 n = self->n[k];
	u32 fan_out = 1 << self->p;
	printf("prepare_side: k=%d, T=%d\n", k, T);
	printf("n=%d\n", n);
	printf("fan_out=%d\n", fan_out);
	u32 tsize = chernoff_bound(n, T * fan_out);
	u32 psize = tsize * T;
	u32 scratch_size = psize * fan_out;
	u32 partition_size = chernoff_bound(n, fan_out);

	printf("side %d, |scratch| = %d items (expansion = %.1f %%), tisze=%d, psize=%d, part_size=%d\n", 
			k, scratch_size, (100.0 * (scratch_size - n)) / n,
				tsize, psize, partition_size);

	
	u64 *scratch = aligned_alloc(CACHE_LINE_SIZE, sizeof(u64) * scratch_size);
	if (scratch == NULL)
		err(1, "failed to allocate scratch space");
	u32 count_size = ROUND(sizeof(u32) * T * fan_out);
	u32 *count = aligned_alloc(CACHE_LINE_SIZE, count_size);
	if (count == NULL)
		err(1, "failed to allocate count");
	u64 *partition = aligned_alloc(CACHE_LINE_SIZE, sizeof(u64) * T * partition_size);
	if (partition == NULL)
		err(1, "failed to allocate partition");

	struct side_t *side = &self->side[k];
	side->L = self->L[k];
	side->n = n;
	side->tsize = tsize;
	side->psize = psize;
	side->scratch = scratch;
	side->count = count;
	side->partition = partition;
	side->partition_size = partition_size;
}

<<Release memory>>=
for (u32 k = 0; k < 2; k++) {
	free(self.side[k].scratch);
	free(self.side[k].count);
	free(self.side[k].partition);
}

@ So now we just have to set-up a ``context''.

<<Prepare task-global variables>>=
struct context_t self;
for (u32 k = 0; k < 3; k++) {
	self.n[k] = n[k];
	self.L[k] = L[k];
}
self.T = omp_get_max_threads();
self.p = p;
self.l = l;
self.result = result;
for (u32 k = 0; k < 2; k++)
	prepare_side(&self, k);


@ \section{Processing Blocks}

We are ready for the big function.



<<Forward declarations>>=
void process_block_v1(struct context_t *self, u32 u, bool verbose);

<<Auxiliary functions>>=
void process_block_v1(struct context_t *self, u32 u, bool verbose)
{
	double start = wtime();
	struct task_result_t * local_result = result_init();
	<<Identify slice of $C$>>
	if (verbose) {
		<<Display stuff>>
	}
	<<Compute change of basis matrix $M$>>
	<<Allocate hash table [[H]]; populate with $CM$>>
	u32 fan_out = 1 << self->p;
	u64 probes = 0;
	#pragma omp parallel reduction(+:probes)
	{
		assert(self->T == (u32) omp_get_num_threads());
		if (verbose)
			printf("partioning...\n");
		for (u32 k = 0; k < 2; k++)
			stage1_partition(&self->side[k], &M, self->p);
		if (verbose)
			printf("subjoins...\n");
		#pragma omp for schedule(dynamic, 1)
		for (u32 i = 0; i < fan_out; i++)
			probes += subjoin(self, H, i, local_result);
	}
	<<Backport solutions>>
	hashtable_free(H);
	result_free(local_result);
	if (verbose) {
		<<Display timing info>>
	}
}

@ The [[self]] object is convenient to pass a bunch of values all at once, but
it is less convenient to write compact code.

@ First, in all cases we will have to compute the change-of-basis matrix.

<<Identify slice of $C$>>=
u64 *C = self->L[2];
u32 l = self->l;
u32 slice_height = 64 - l;
u32 lo = u * slice_height;
u32 hi = MIN((u + 1) * slice_height, self->n[2]);
slice_height = hi - lo;


<<Display stuff>>=
printf("Block %d: C[%d:%d] (slice_height=%d)\n", u, lo, hi, hi - lo);

<<Compute change of basis matrix $M$>>=
struct matmul_table_t M, M_inv;
u32 rank = basis_change_matrix(C, lo, hi, &M, &M_inv);
if ((rank != slice_height) && verbose)
	printf("---> Rank deffect (%d)\n", slice_height - rank);
l = 64 - rank;                          /* update l in case of rank deffect */


@ The technical part consists in computing $AM \join_\ell BM$. For now, let
us assume that the join has been computed, that solutions have been found, and
let us deal with the aftermath.

In [[local_result]], we have ``solutions'' of the $(AM, BM, CM)$ instance, i.e. 
triplets $(xM, yM, zM)$, so we multiply them by $M^{-1}$ to get the actual 
solutions.

<<Backport solutions>>=
struct solution_t *loc = local_result->solutions;
u32 n_sols = local_result->size;
for (u32 i = 0; i < n_sols; i++) {
	u64 x = gemv(loc[i].x, &M_inv);
	u64 y = gemv(loc[i].y, &M_inv);
	u64 z = gemv(loc[i].z, &M_inv);
	report_solution(self->result, x, y, z);
}

<<Display timing info>>=
double duration = wtime() - start;
printf("Block %d, total time: %.1fs\n", u, duration);
double in_volume = 9.5367431640625e-07 * (self->n[0] + self->n[1]);
double out_volume =  9.5367431640625e-07 * probes;
double volume = in_volume + out_volume;
double rate = volume / duration;
printf("Join volume: %.1fM item [IN=%.1fM, OUT=%.1fM] (%.1fM item/s)\n", 
					volume, in_volume, out_volume, rate);


<<Allocate hash table [[H]]; populate with $CM$>>=
u64 CM[slice_height];
for (u32 i = 0; i < slice_height; i++)
	CM[i] = gemv(C[i + lo], &M);
struct hash_table_t *H = hashtable_build(CM, 0, slice_height);


@ \section{Join v1: Partitioning Join}

The partitionning function is meant to be executed by all threads. Upon return, 
the [[count]] parameter reveals the extent of each thread-bucket.

<<Forward declarations>>=
void stage1_partition(struct side_t *self, const struct matmul_table_t * M, u32 p);

<<Auxiliary functions>>=
void stage1_partition(struct side_t *side, const struct matmul_table_t * M, u32 p)
{ 
	u32 tid = omp_get_thread_num();
	u32 fan_out = 1 << p;
	// printf("stage 1 partitioning, fan_out=%d, tid=%d, tsize=%d\n", fan_out, tid, side->tsize);
	u32 *count = side->count + tid * fan_out;
	for (u32 i = 0; i < fan_out; i++)
		count[i] = side->psize * i + side->tsize * tid;
	const u64 *L = side->L;
	const u32 n = side->n;
	u64 *scratch = side->scratch;
	#pragma omp for schedule(static)
	for (u32 i = 0; i < n; i++) {
		u64 x = gemv(L[i], M);
		u32 h = x >> (64 - p);
		//assert(h < fan_out);
		u32 idx = count[h]++;
		//printf("%d, %d: %d\n", tid, h, idx - (side->psize * h + side->tsize * tid));
		//const u32 ub = side->psize * h + side->tsize * (tid + 1);
		//if (idx >= ub)
		//	errx(1, "bucket overflow. Thread %d, i=%d\n", tid, h);
		scratch[idx] = x;
	}
}

@ \section{Sub-joins}

blabla

<<Forward declarations>>=
u64 subjoin(struct context_t *self, const struct hash_table_t *H, u32 i, struct task_result_t *result);

<<Auxiliary functions>>=
u64 subjoin(struct context_t *self, const struct hash_table_t *H, u32 i, struct task_result_t *result)
{
	u32 tid = omp_get_thread_num();
	u32 T = omp_get_num_threads();
	u64 *sorted[2];
	u32 N[2];
	for (u32 k = 0; k < 2; k++) {
		<<Copy partition [[i]] to (contiguous) [[partition]]>>
		qsort(partition, n, sizeof(u64), cmp);
	}
	return merge_join(sorted[0], N[0], sorted[1], N[1], self->l, H, result);
}


<<Copy partition [[i]] to (contiguous) [[partition]]>>=
u32 fan_out = 1 << self->p;
struct side_t *side = &self->side[k];
u32 psize = side->psize;
u32 tsize = side->tsize;
u64 *partition = side->partition + tid * side->partition_size;
u32 *count = side->count;
u64 *scratch = side->scratch;
u32 n = 0;
for (u32 j = 0; j < T; j++) {
	u32 lo = psize * i + tsize * j;
	u32 hi = count[j * fan_out + i];
	/* this could be a memcpy */
	for (u32 it = lo; it < hi; it++)
		partition[n++] = scratch[it];
}
N[k] = n;
sorted[k] = partition;

@ We again use the stupidest possible sort, and we do the merge-join as in the
v0.

<<Forward declarations>>=
int cmp(const void *a_, const void *b_);

<<Auxiliary functions>>=
int cmp(const void *a_, const void *b_)
{
	u64 *a = (u64 *) a_;
	u64 *b = (u64 *) b_;
	return (*a > *b) - (*a < *b);
}


<<Forward declarations>>=
u64 merge_join(const u64 *a, u32 Na, const u64 *B, u32 Nb, u32 l, const struct hash_table_t *H, struct task_result_t *result);

<<Auxiliary functions>>=
u64 merge_join(const u64 *A, u32 Na, const u64 *B, u32 Nb, u32 l, const struct hash_table_t *H, struct task_result_t *result)
{
	u64 probes = 0;
	u32 i = 0;
	u32 j = 0;
	u64 mask = LEFT_MASK(l);
	while (i < Na && j < Nb) {
		u64 prefix_a = A[i] & mask;
		u64 prefix_b = B[j] & mask;
		if (prefix_a < prefix_b) {
			i += 1;
			continue;
		}
		if (prefix_a > prefix_b) {
			j += 1;
			continue;
		}
		/* Here, prefix_a == prefix_b */
		u32 j_0 = j;
		while (1) {
			probes++;
			u64 c = A[i] ^ B[j];
			if (hashtable_lookup(H, c))
				report_solution(result, A[i], B[j], c);
			j += 1;
			if (j < Nb && (B[j] & mask) == prefix_b)
				continue;
			i += 1;
			if (i < Na && (A[i] & mask) == prefix_a) {
				j = j_0;
				continue;
			}
			break;
		}
	}
	return probes;
}


@ \end{document}
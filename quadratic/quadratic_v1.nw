\documentclass{book}

\usepackage{geometry}
\usepackage{noweb}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{parskip}
\usepackage{xspace}
\usepackage{hyperref}

% knuth-style algos
\newcommand{\slug}{\hbox{\kern1.5pt\vrule width2.5pt height6pt depth1.5pt\kern1.5pt}}
\def\xskip{\hskip 7pt plus 3pt minus 4pt}
\newdimen\algindent
\newif\ifitempar \itempartrue % normally true unless briefly set false
\def\algindentset#1{\setbox0\hbox{{\bf #1.\kern.25em}}\algindent=\wd0\relax}
\def\algbegin #1 #2{\algindentset{#21}\alg #1 #2} % when steps all have 1 digit
\def\alg#1(#2). {\medbreak % Usage: \algbegin Algorithm A (algname). This...
  \noindent{\bf#1}({\it#2\/}).\xskip\ignorespaces}
\def\algstep#1.{\ifitempar\smallskip\noindent\else\itempartrue
  \hskip-\parindent\fi
  \hbox to\algindent{\bf\hfil #1.\kern.25em}%
  \hangindent=\algindent\hangafter=1\ignorespaces}


\begin{document}

\setcounter{chapter}{2}
\chapter{The Quadratic Algorithm}

% quadratic ---> N^2 * 16 instr.
% ijoux     ---> N^2/32 (16 instr. GEMM + 64 instr. join)


This file describes an implementation of the quadratic algorithm. It is plain C.

PowerPC A2 : 26.8Mpair/s, 37.2 Mpair/s with SMT4. 

update PowerPC A2 : 27.3Mpair/s. 15 instructions / pair. Peak --> 100Mpair/s per core

The main function described in this file ``solves'' a task. Once all tasks are
solved, the original instance has been solved. 

<<*>>=
#include <math.h>
#include <stdlib.h>
#include <stdio.h>
#include <assert.h>
#include <err.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <byteswap.h>

#include <papi.h>

#include "common.h"
#include "datastructures.h"

<<Type definitions>>
<<Forward declarations>>
<<Auxiliary functions>>
<<The main function>>

@ \section{Processing Tasks}

 ``Solving the task'' means finding all pairs $(x, y)$ of 64-bits integers such
that $x \in A^{[i]}, y \in B^{[j]}$ and $x \oplus y \in C^{[i \oplus j]}$. 

<<The main function>>=
struct task_result_t * quadratic_task(const char *hash_dir, struct task_id_t *task)
{
	static const bool verbose = false;
	<<Prepare [[result]]>>
	printf("[%.1f] task launch\n", wtime());
	<<Allocate memory and load data from disk>>
	<<Determine the block size ($\ell$)>>
	<<Split the task into blocks and chunks>>
	if (verbose) {
		<<Display some info>>
	}
	<<Prepare context>>
	printf("[%.1f] task launch\n", wtime());
	for (u32 u = 0; u < grid_size; u++)
		process_block(&self, u, verbose);
	<<Release memory>>
	printf("[%.1f] task stop\n", wtime());
	return result;
}


@ The number of solutions of a task is not known in advance, but it should be 
fairly small. We use a dynamic array to store them. Resizing is unlikely.
	

<<Prepare [[result]]>>=
struct task_result_t *result = malloc(sizeof(*result));
if (result == NULL)
	err(1, "cannot allocate task result object");
result->size = 0;
result->capacity = 128;
result->solutions = malloc(result->capacity * sizeof(struct solution_t));

@ When a new solution is found, it is appended to [[result]].

<<Auxiliary functions>>=
void report_solution(struct task_result_t *result, u64 x, u64 y)
{
	printf("solution %016" PRIx64 " ^ %016" PRIx64 " in A\n", x, y);
	if (result->size == result->capacity) {
		result->solutions = realloc(result->solutions, 2 * result->capacity);
		if (result->solutions == NULL)
			err(1, "failed to re-alloc solutions array");
		result->capacity *= 2;
	}
	result->solutions[result->size].x = x ^ y;
	result->solutions[result->size].y = x;
	result->solutions[result->size].z = y;
	result->size++;
}

@ \subsection{Preparations}

As a result of the preprocessing, each list should be split into $2^k$ hash files,
along with indexes. This greatly simplifies the quadratic algorithm. We just have to
load the right hash files and the corresponding indexes, and that's it.

<<Allocate memory and load data from disk>>=
u64 *slice[3];
u32 size[3];
for (int kind = 0;  kind < 3; kind++) {	
	<<Determine [[filename]]>>
	<<Get file size and allocate memory>>
	<<Open file and load hashes>>
}


<<Determine [[filename]]>>=
char filename[255];
char *kind_name[3] = {"foo", "bar", "foobar"};
sprintf(filename, "%s/%s.%03x", hash_dir, kind_name[kind], task->idx[kind]);


@ When allocating the memory, we enforce alignement 
on a 64-byte boundary (the size of a cache line on x86 CPUs). 
This allows aligned access for all possible sizes, including 256-bit registers.
For this, we use [[aligned_alloc]], available in \textsf{C11}.

<<Get file size and allocate memory>>=
struct stat infos;
if (stat(filename, &infos))
	err(1, "fstat on %s", filename);
u64 aligned_size = 64 * (1 + infos.st_size / 64);
slice[kind] = aligned_alloc(64, aligned_size);
if (slice[kind] == NULL)
	err(1, "failed to allocate memory");
size[kind] = infos.st_size / sizeof(u64);

<<Open file and load hashes>>=
FILE *f = fopen(filename, "r");
if (f == NULL)
	err(1, "fopen failed (%s)", filename);
u32 check = fread(slice[kind], 1, infos.st_size, f);
if ((check != (size_t) infos.st_size) || ferror(f))
	err(1, "fread : read %d, expected %zd", check, infos.st_size);
if (fclose(f))
	err(1, "fclose %s", filename);

@ One important caveat: hash files are stored in \emph{little-endian} order. 
If this code is running on a PowerPC machine, we need to swap everything.

<<Open file and load hashes>>=
if (big_endian()) {
	for (u32 i = 0; i < size[kind]; i++)
		slice[kind][i] = bswap_64(slice[kind][i]);
}


<<Release memory>>=
for (u32 kind = 0;  kind < 3; kind++) {
	free(slice[kind]);
}

@ At this stage, the hashes needed to perform the task are loaded.
We now determine the $\ell$ parameter, i.e. the grid size. For now, 
we use a heuristic: we make sure that the subslice of $A$ has less 
than 512 hashes (this corresponds to a hash table fill of $0.25$).

<<Determine the block size ($\ell$)>>=
u32 l = ceil(log2(size[0] / 512)) + 1;
u32 grid_size = 1 << l;

@ To split the task into a grid, we compute sub-slices boundaries. On $A$, this 
delimits blocks. On $B$ and $C$, this delimits chunks. To perform this partition, 
we must compute $\ell$-bit prefix boundaries. I have screwed this up so many times
that I had to write down the precise algorithm.

\algbegin Algorithm P (prefix index). Given a sorted array $A$ of size $n$, produce an
index array $I$ such that entries of $A$ whose $k$-bit prefix is $x$ are located at 
indices [[I[x]:I[x + 1]]].

\algstep P1. [Iinitialization.] Set $x \gets 0, i \gets 0$ and $I[0] \gets 0$.

\algstep P2. [Skip $x$.] While $i < N$ and $prefix(A[i]) = x$, increment $i$. 
            (At the end of this step, we know that the slice of $A$ with prefix $x$
            is at $I[x]:i$).

\algstep P3. [End of $x$.] Set $I[x + 1] \gets i$. If $x = 2^k$, stop the algorithm.
                           Otherwise, increment $x$ and return to step P2.

\medskip

Now let's translate this into code.

<<Split the task into blocks and chunks>>=
u32 index[3][grid_size + 1];
for (u32 kind = 0; kind < 3; kind++) {
	index[kind][0] = 0;
	u32 i = 0;
	for (u32 prefix = 0; prefix < grid_size; prefix++) {	
		while ((i < size[kind]) && ((slice[kind][i] >> (64ull - l)) == prefix))
			i++;
		index[kind][prefix + 1] = i;
	}
	
	/* verification */
	for (u32 prefix = 0; prefix < grid_size; prefix++)
		for (u32 it = index[kind][prefix]; it < index[kind][prefix + 1]; it++)
			assert((slice[kind][it] >> (64ull - l)) == prefix);
}


@ If requested, we are capable of displaying some information.

<<Display some info>>=
	/* task-level */
printf("Task: |A|=%d,  |B|=%d,  |C|=%d\n", size[0], size[1], size[2]);
double mbytes = 8. * (size[0] + size[1] + size[2]) / 1048576.0;
double mpairs = ((double) size[1]) * ((double) size[2]) / 1048576.0; 
printf("Task volume : %.1fMbyte of hashes, %.1fMpair\n", mbytes, mpairs);
printf("Est. time : %.0fs\n", mpairs / 1000);
double logsols = log2(size[0]) + log2(size[1]) + log2(size[2]);
printf("Est. #solutions : %g\n", pow(2, logsols - 64));
	/* block-level */
double shared_slice = size[0] / grid_size;
int hash_size = hashtable_size(shared_slice);
printf("Using l = %d\n", l);
printf("Average block slice volume : %.0f bytes (%.0f hashes). |hash| = %d entries (%d bytes)\n", 
	8 * shared_slice, shared_slice, hash_size, 8 * hash_size);
	/* chunk-level */
double kbytes = 8 * (size[0] + size[1] + size[2]) / grid_size / 1024.;
mpairs = (size[1] / grid_size) * (size[2] / grid_size) / 1048576.; 
printf("Average chunk volume : %.1fKbyte of hashes, %.3fMpair\n", kbytes, mpairs);
printf("\n");



@ \subsection{Processing Blocks and Chunks}

Most functions defined below need to access the slices, the indexes and the solutions. 
Therefore, we encapsulate all this into a ``context'' object.

<<Type definitions>>=
struct context_t {
	struct task_result_t *result;
	u32 k;
	u32 grid_size;
	u64 *slice[3];
	u32 *index[3];
};

<<Prepare context>>=
struct context_t self;
self.k = task->k;
self.result = result;
self.grid_size = grid_size;
for (u32 i = 0; i < 3; i++) {
	self.slice[i] = slice[i];
	self.index[i] = index[i];
}

@ In a CPU core, blocks are processed sequentially (on a GPU, many blocks would be 
processed simultaneously on all available multiprocessors). In a block, a small
slice of $A$ is loaded into a datastructure with fast membership test. Then, all 
chunks exploit this datastructure.

The ``failsafe'' hash table is always built. It is used as a fallback when the
cuckoo table cannot be built, or when the cuckoo table reports a solution
(which may be a false positive).

<<Forward declarations>>=
void process_block(struct context_t *self, u32 u, bool verbose);
void hard_chunk(struct context_t *self, const struct hash_table_t *D, 
       u32 B_lo, u32 B_hi, u32 C_lo, u32 C_hi);
u32 easy_chunk(struct context_t *self, const u32 *H,
	const struct hash_table_t *D, u32 B_lo, u32 B_hi, u32 C_lo, u32 C_hi);

<<Auxiliary functions>>=
void process_block(struct context_t *self, u32 u, bool verbose)
{
	double start = wtime();
	// u64 clock = ticks();
	float rtime = 0, ptime = 0, ipc = 0;
	long long ins = 0;
	
	int rc = PAPI_ipc(&rtime, &ptime, &ins, &ipc);
	if (rc < PAPI_OK)
    		errx(1, "PAPI_ipc : %d (%s)", rc, PAPI_strerror(rc));

	u32 grid_size = self->grid_size;
	if (verbose)
		printf("Doing block %d/%d...", u, grid_size - 1);
	u64 *A = self->slice[0];
	u32 *A_idx = self->index[0];
	u32 *idx_B = self->index[1];
	u32 *idx_C = self->index[2];
	struct hash_table_t *D = hashtable_build(A, A_idx[u], A_idx[u + 1]);
	u32 *H = cuckoo_build(A, A_idx[u], A_idx[u + 1]);
	u64 n_pairs = 1;
	u32 slow = 0;
	for (u32 v = 0; v < grid_size; v++) {	
		u32 B_lo = idx_B[v];
		u32 B_hi = idx_B[v + 1];
		u32 C_lo = idx_C[u ^ v];
		u32 C_hi = idx_C[(u ^ v) + 1];
		n_pairs += (B_hi - B_lo) * (C_hi - C_lo);
		if (H != NULL)
			slow += easy_chunk(self, H, D, B_lo, B_hi, C_lo, C_hi);
		else
			hard_chunk(self, D, B_lo, B_hi, C_lo, C_hi);
	}

	if (verbose) {
		double wall = wtime() - start;
		// u64 cycles = ticks() - clock;
		double rate = (1.0 * n_pairs) / wall;
		// double inv_throughput = (1.0 * cycles) / n_pairs;
		// printf("Rate: %.1fMpair/s / %.1f cycle/pair. ", rate / (1024 * 1024), inv_throughput);
		printf("Rate: %.1fMpair/s [slow=%d] ", rate / (1024 * 1024), slow);
		u32 n_tasks = 1 << (2 * self->k);
		double total = (1.0 * n_tasks) * n_pairs / rate * (self->grid_size);
		printf("Est. total computation time: %.2e h\n", total / 3600);

		int rc = PAPI_ipc(&rtime, &ptime, &ins, &ipc);
		if (rc < PAPI_OK)
    			errx(1, "PAPI_ipc : %d", rc);
    		printf("IPC:    %.1f\n", ipc);
    		printf("I/pair: %.1f\n", (1.0 * ins) / n_pairs);

    		//int Events[2] = { PAPI_TOT_CYC, PAPI_TOT_INS };
		long long values[2];
		if (PAPI_stop_counters(values, 2) != PAPI_OK)
    			errx(1, "PAPI_stop_counters");
	}
	hashtable_free(D);
	free(H);
}


@ Let's get down to the nitty-gritty of processing a chunk. It comes down to
probing the datastructure holding a small slice of $A$ will all pairs in the
matching slices of $B$ and $C$.

The hard case is the easiest... to write-down.

<<Auxiliary functions>>=
void hard_chunk(struct context_t *self, const struct hash_table_t *D, 
       u32 B_lo, u32 B_hi, u32 C_lo, u32 C_hi)
{
	u64 *B = self->slice[1];
	u64 *C = self->slice[2];
	for (u32 r = B_lo; r < B_hi; r++)
		for (u32 s = C_lo; s < C_hi; s++)
			if (!hashtable_lookup(D, B[r] ^ C[s]))
				continue;
			else
				report_solution(self->result, B[r], C[s]);
}


@ When the cuckoo table is available, then things... can be quite similar. 
However, Because we would like to vectorize everything, we first define a 
``rolled'' version, which will enable us to do some unrolling.

<<Auxiliary functions>>=
u32 easy_chunk(struct context_t *self, const u32 *H,
		const struct hash_table_t *D, u32 B_lo, u32 B_hi, u32 C_lo, u32 C_hi)
{
	u32 slow = 0;
	u64 *B = self->slice[1];
	u64 *C = self->slice[2];
	for (u32 r = B_lo; r < B_hi; r++) {
		u64 x = B[r];
		for (u32 s = C_lo; s < C_hi; s++)
			if (!cuckoo_lookup(H, x ^ C[s]))
				continue;
			else {
				if (hashtable_lookup(D, x ^ C[s]))
					report_solution(self->result, B[r], C[s]);
				slow++;
			}
	}
	return slow;
}

@ \end{document}
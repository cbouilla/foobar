\documentclass{book}

\usepackage[a4paper,vmargin=1in]{geometry}
\usepackage{noweb}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{parskip}
\usepackage{xspace}
\usepackage{hyperref}


\begin{document}

\setcounter{chapter}{2}
\chapter{The Quadratic Algorithm}


This file describes an implementation of the quadratic algorithm. 

The main function described in this file ``solves'' a task. Once all tasks are
solved, the original instance has been solved. 

<<*>>=
#include <math.h>
#include <stdlib.h>
#include <stdio.h>
#include <err.h>
#include <sys/types.h>
#include <sys/stat.h>

#include "common.h"
#include "datastructures.h"

<<The main function>>

@ \section{Processing Tasks}

 ``Solving the task'' means finding all pairs $(x, y)$ of 64-bits integers such
that $x \in A^{[i]}, y \in B^{[j]}$ and $x \oplus y \in C^{[i \oplus j]}$. 

<<The main function>>=
struct task_result_t * quadratic_task(const char *hash_dir, struct task_t *task)
{
	static const bool verbose = true;
	double start = wtime();
	u64 clock = ticks();
	struct task_result_t *result;
	<<Prepare [[result]]>>
	<<Allocate memory and load data from disk>>
	<<Determine the block size ($\ell$)>>
	<<Split the task into blocks and chunks>>
	if (verbose) {
		<<Display some info>>
	}

	<<Process all the blocks>>
	<<Release memory>>
	if (verbose) {
		<<Display timing results>>
	}
	return result;
}


<<Display timing results>>=
double wall = wtime() - start;
u64 cycles = ticks() - clock;
double n_pairs = (1.0 * size[1]) * (1.0 * size[2]);
double rate = n_pairs / wall;
double inv_throughput = cycles / n_pairs;
printf("Wall time: %.1fs, %" PRId64 " CPU ticks.\n", wall, cycles);
printf("Rate: %.1fMpair/s / %.1f cycle/pair.\n", rate / (1024 * 1024), inv_throughput);


<<Display some info>>=
	/* task-level */
double mbytes = 8. * (size[0] + size[1] + size[2]) / 1048576.0;
double mpairs = ((double) size[1]) * ((double) size[2]) / 1048576.0; 
printf("\n");
printf("Task volume : %.1fMbyte of hashes, %.1fMpair\n", mbytes, mpairs);
printf("Exp. time : %.0fs\n", mpairs / 100);
	/* block-level */
double shared_slice = size[0] / grid_size;
int hash_size = hashtable_size(grid_size);
printf("Using l = %d\n", l);
printf("Average block slice volume : %.0f bytes (%.0f hashes). |hash| = %d entries (%d bytes)\n", 
	8 * shared_slice, shared_slice, hash_size, 8 * hash_size);
	/* chunk-level */
double kbytes = 8 * (size[0] + size[1] + size[2]) / grid_size / 1024.;
mpairs = (size[1] / grid_size) * (size[2] / grid_size) / 1048576.; 
printf("Average chunk volume : %.1fKbyte of hashes, %.3fMpair\n", kbytes, mpairs);
printf("\n");

@ The number of solutions of a task is not known in advance, but it should be 
fairly small. We use a dynamic array to store them. Resizing is unlikely.
	

<<Prepare [[result]]>>=
result = malloc(sizeof(*result));
if (result == NULL)
	err(1, "cannot allocate task result object");
result->size = 0;
result->capacity = 128;
result->solutions = malloc(result->capacity * sizeof(struct solution_t));

@ When a new solution is found, it is appended to [[result]].

<<Report $x, y$ as a solution>>=
if (verbose)
	printf("solution %016" PRIx64 " ^ %016" PRIx64 " in A\n", x, y);
if (result->size == result->capacity) {
	result->solutions = realloc(result->solutions, 2 * result->capacity);
	if (result->solutions == NULL)
		err(1, "failed to re-alloc solutions array");
	result->capacity *= 2;
}
result->solutions[result->size].x = x;
result->solutions[result->size].y = y;
result->size++;

@ \subsection{Preparations}

As a result of the preprocessing, each list should be split into $2^k$ hash files,
along with indexes. This greatly simplifies the quadratic algorithm. We just have to
load the right hash files and the corresponding indexes, and that's it.

<<Allocate memory and load data from disk>>=
u64 *slice[3];
u32 size[3];
for (int kind = 0;  kind < 3; kind++) {	
	<<Determine [[filename]]>>
	<<Get file size and allocate memory>>
	<<Open file and load hashes>>
}

<<Determine [[filename]]>>=
char filename[255];
char *kind_name[3] = {"foo", "bar", "foobar"};
sprintf(filename, "%s/%s.%03x", hash_dir, kind_name[kind], task->idx[kind]);

<<Get file size and allocate memory>>=
struct stat infos;
if (stat(filename, &infos))
	err(1, "fstat on %s", filename);
slice[kind] = malloc(infos.st_size);
if (slice[kind] == NULL)
	err(1, "failed to allocate memory");
size[kind] = infos.st_size / sizeof(u64);

<<Open file and load hashes>>=
FILE *f = fopen(filename, "r");
if (f == NULL)
	err(1, "fopen failed (%s)", filename);
u32 check = fread(slice[kind], 1, infos.st_size, f);
if ((check != (size_t) infos.st_size) || ferror(f))
	err(1, "fread : read %d, expected %zd", check, infos.st_size);
if (fclose(f))
	err(1, "fclose %s", filename);


<<Release memory>>=
for (u32 kind = 0;  kind < 3; kind++) {
	free(slice[kind]);
}

@ At this stage, the hashes needed to perform the task are loaded.
We now determine the $\ell$ parameter, i.e. the grid size. For now, 
we use a heuristic: we make sure that the subslice of $A$ has less 
than 512 hashes (this corresponds to a hash table fill of $0.25$).

<<Determine the block size ($\ell$)>>=
u32 l = floor(log2(size[0] / 512));
u32 grid_size = 1 << l;

@ To split the task into a grid, we compute sub-slices boundaries. On $A$, this 
delimits blocks. On $B$ and $C$, this delimits chunks. To perform this partition, 
we must compute $\ell$-bit prefix boundaries.

<<Split the task into blocks and chunks>>=
u32 index[3][grid_size + 1];
for (u32 kind = 0; kind < 3; kind++) {
	u32 h_prefix = 0;
	index[kind][0] = 0;
	u32 i = 0;
	for (u32 prefix = 0; prefix < grid_size; prefix++) {
		while ((i < size[kind]) && (h_prefix <= prefix)) {
			h_prefix = slice[kind][i] >> (64ull - l);
			i++;
		}
		index[kind][prefix + 1] = i - 1;
	}
	index[kind][grid_size] = size[kind];
}

@ \subsection{Processing Blocks and Chunks}

In a CPU core, blocks are processed sequentially (on a GPU, many blocks would be 
processed simultaneously on all available multiprocessors). In a block, a small
slice of $A$ is loaded into a datastructure $\mathcal{D}$ with fast membership 
test. Then, all chunks exploit this datastructure.

<<Process all the blocks>>=
for (u32 u = 0; u < grid_size; u++) {
	if (verbose)
		printf("\rBlock %d/%d\n", u, grid_size);
	<<Process block $u$>>
}

<<Process block $u$>>=
struct hash_table_t *D;
const u32 A_lo = index[1][u];
const u32 A_hi = index[1][u + 1];
D = hashtable_build(slice[0], A_lo, A_hi);
for (u32 v = 0; v < grid_size; v++) {
	<<Process chunk $(u, v)$>>
}
hashtable_free(D);


@ Let's get down to the nitty-gritty of processing a chunk. It comes down to
probing the datastructure holding a small slice of $A$ will all pairs in the
matching slices of $B$ and $C$.

<<Process chunk $(u, v)$>>=
const u32 B_lo = index[1][v];
const u32 B_hi = index[1][v + 1];
const u32 C_lo = index[2][u ^ v];
const u32 C_hi = index[2][(u ^ v) + 1];
//if (verbose)
//	printf("Chunk (%d, %d) : [%d:%d] * [%d:%d]\n", u, v, B_lo, B_hi, C_lo, C_hi);
for (u32 r = B_lo; r < B_hi; r++) {
	const u64 x = slice[1][r];
	for (u32 s = C_lo; s < C_hi; s++) {
		const u64 y = slice[2][s];
		<<Check pair $(x, y)$>>
	}
}

<<Check pair $(x, y)$>>=
if (hashtable_lookup(D, x ^ y)) {
	<<Report $x, y$ as a solution>>
}

@ \end{document}
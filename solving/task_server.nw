\documentclass{article}

\usepackage[a4paper]{geometry}
\usepackage{noweb}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{parskip}
\usepackage{xspace}

\newcommand{\CEE}{\texttt{C}\xspace}
\usepackage{tikz}
\usetikzlibrary{arrows,automata}

\newcommand{\ZMQ}{\textsf{$\varnothing$MQ}\xspace}

\begin{document}

\title{An Application-Agnostic Task Server}
\author{Charles Bouillaguet}

\maketitle

\section{Introduction} 

I only have access to computing environments where either I cannot choose when
my programs will run, or their running time is fairly limited, or they can be
interrupted at any moment. To run long, distributed computations in these
environnment I resorted to a classic client-server strategy: a long-running
server distributes \emph{tasks} to the clients and collects the \emph{results}
of these tasks once they are completed. Once a clients starts running, it
sends a \emph{task request} to the server. If the client is brutally
interrupted, then the task \emph{completion notice} will never be sent back to
the server. At some point, the server considers that the task is expired, and
it will send it to another client.

The server is light-weight and application-agnostic. Tasks are simply
integers, and their number is the only parameter of the server. The task
results are stored and not interpreted. I hope that this makes the server
reusable in a variety of contexts.

The server is (almost) stateless. It can be restarted at any time without
problem. It could have used the \textsf{HTTP} protocol, but instead it uses the
\ZMQ library to handle networking, in part because \ZMQ handles failures more
gracefully (and does a fraction of the job for us).

The global structure of the server program is classical.

<<*>>=
#define _XOPEN_SOURCE 500
<<Header files to include>>
<<Type definitions>>
<<Global variables>>
<<Functions>>
<<The main program>>


@ The main program is typical of a server.

<<The main program>>=
int main(int argc, char **argv)
{
	<<Set sensible default settings>>
	<<Process the command line>>
	<<Initialize $N$ [[PENDING]] tasks>>
	<<Open journal file for reading; Mark completed tasks as [[DONE]]>>
	<<Reopen the journal file for append>>
	<<Initialize networking>>
	<<Main server loop>>
}

@ Let us deal with the inevitable first: the inclusion of standard headers. The
\texttt{server.h} file contains type declaration shared between the server and
other programs.

<<Header...>>=
#include <stdlib.h>
#include <stdio.h>
#include <err.h>
#include <getopt.h>
#include <sys/time.h>
#include <string.h>
#include <assert.h>
#include "server.h"

@ Also inevitable, and rather boring, is the processing of command-line
options. The server takes four parameters:
\begin{itemize}
\item The number of tasks $N$ (mandatory).
\item The network address at which to listen (optional).
\item The name of the ``journal file'' to which task results are written
  (optional).
\item The duration after which tasks are in timeout and must be restarted.
\end{itemize}

We use the standard POSIX |getopt()| function to deal with command-line options.

<<Global...>>=
struct option longopts[5] = {
		{"N", required_argument, NULL, 'N'},
		{"journal-file", required_argument, NULL, 'j'},
		{"server-address", required_argument, NULL, 'a'},
		{"timeout", required_argument, NULL, 't'},
		{NULL, 0, NULL, 0}
};
int N = -1;
char *server_address = NULL;
char *journal_filename = NULL;
int task_timeout;

@ By default, the journal file is called \texttt{journal.log}, the server
address is \verb#tcp://*:5555# (which means ``all network interfaces on port
5555'') and tasks are rescheduled after 3600s.

<<Global variables>>=
static const char * DEFAULT_FILENAME = "journal.log";
static const char * DEFAULT_ADDRESS = "tcp://*:5555";
static const int DEFAULT_TIMEOUT = 3600;

<<Set sensible...>>=
server_address = strdup(DEFAULT_ADDRESS);
journal_filename = strdup(DEFAULT_FILENAME);
task_timeout = DEFAULT_TIMEOUT;

<<Process the command line>>=
char ch;
while ((ch = getopt_long(argc, argv, "", longopts, NULL)) != -1) {
	switch (ch) {
	case 'N':
		N = atoi(optarg);
		break;
	case 'a':
		server_address = optarg;
		break;
	case 'j':
		journal_filename = optarg;
		break;
	case 't':
		task_timeout = atoi(optarg);
		break;
	default:
		errx(1, "Unknown option\n");
	}
}
if (N < 0)
    errx(1, "missing argument --N");

@ We try to estimate the total time spent in performing tasks. For
this, we rely on the following function that returns the wall-clock
time (in seconds since the epoch) as a [[double]].

<<Functions>>=
double wtime()
{
	struct timeval ts;
	gettimeofday(&ts, NULL);
	return ts.tv_sec + (ts.tv_usec / 1e6);
}


@ \section{Tasks}

Tasks are simple integers in the range $[0; N[$. A task can be pending
execution, being run, or completed.

\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,node distance=4.5cm,
		      every state/.style={draw, outer sep=0pt,shape=rectangle},
		      accepting/.style={accepting by arrow, accepting where=below},
		      uplink/.style={transform canvas={yshift=1mm}},
		      downlink/.style={transform canvas={yshift=-1mm}}]

  \node[initial above,state]   (P)               {[[PENDING]]};
  \node[state]                 (R) [right of=P]  {[[RUNNING]]};
  \node[state,accepting] (D) [right of=R]  	 {[[DONE]]};

  \path (P) edge [uplink]   node[above] {task request} (R)
	(R) edge [downlink] node[below] {timeout}      (P)
	    edge            node[above] {task result}  (D);

  \draw (P) .. controls (3cm, -2cm) and (6cm, -2cm) .. node[below] {found in \texttt{journal.log}} (D);
\end{tikzpicture}
\end{center}


The tasks are arranged in three lists (one
by task state) ; they move between lists at they are executed, completed
or when they expire. We thus use doubly-linked lists.

<<Type...>>=
enum state_t { PENDING, RUNNING, DONE };
struct task_t {
	int id;                /* this is task number |id| */
	enum state_t state;
	double since;          /* time of last state change */
	struct task_t *prev, *next;
};
 

@ The task lists are ordered: tasks are always added at the end of the
list. They can be removed arbitrarily, and access to the first task of the list
must be efficient. We thus keep pointers to the |first| and |last| item of each
list. 

<<Global...>>=
int N;                   /* total number of tasks */
struct task_t *tasks;    /* all tasks */
int n_tasks[3];          /* number of tasks in each state */
struct task_t *first[3]; /* first item of each list */
struct task_t *last[3];  /* last item of each list */


@ When the server starts, $N$ tasks are created, and they are all pending
execution. The [[tasks]] array holding all the tasks is dynamically allocated (it
allows direct access to the tasks by index), and the chained links are
setup. Note that the global variables [[n_tasks]], [[first]] and [[last]] are
initialized to zero, as per the \CEE language specification.

<<Initialize $N$ [[PENDING]] tasks>>=
tasks = malloc(N * sizeof(struct task_t));
if (tasks == NULL)
	err(1, "failed to allocate all tasks");
for (int i = 0; i < N; i++) {
	tasks[i].id = i;
	tasks[i].state = PENDING;
}
tasks[0].prev = NULL;
for (int i = 1; i < N; i++)
	tasks[i].prev = &tasks[i - 1];
for (int i = 0; i < N - 1; i++)
	tasks[i].next = &tasks[i + 1];
tasks[N-1].next = NULL;
first[PENDING] = &tasks[0];
last[PENDING] = &tasks[N - 1];
n_tasks[PENDING] = N;


@ When tasks change state, the links must be adjusted. This is classical
doubly-linked lists manipulation.

<<Functions>>=
void set_task_state(int i, enum state_t new_state)
{
	struct task_t *t = &tasks[i];
	t->since = wtime();
	<<Remove [[t]] from its current list>>
	<<Append [[t]] at the right end of the target list>>
}

<<Remove [[t]]...>>=
if (t->prev != NULL) 
	t->prev->next = t->next;
else 
	first[t->state] = t->next;

if (t->next != NULL)
	t->next->prev = t->prev;
else 
	last[t->state] = t->prev;
n_tasks[t->state]--;

<<Append [[t]]...>>=
t->state = new_state;
t->prev = last[new_state];
if (t->prev != NULL)
	t->prev->next = t;
else 
	first[new_state] = t;
last[new_state] = t;
t->next = NULL;
n_tasks[new_state]++;

  
@ If a client is interrupted, the result of the task it was processing will
never be returned, and the task must be restarted at a later time. The server
detects this using a timeout mecanism. Tasks that have been attributed to a
client appear in the list of |RUNNING| tasks in increasing order of start
date. Checking for expired tasks amounts to check the first entries of this list.

<<Check for expired tasks...>>=
double threshold = wtime() - task_timeout;
while (first[RUNNING] != NULL && first[RUNNING]->since < threshold) {
	printf("Task %d timeout after %.0fs\n", first[RUNNING]->id, 
			wtime() - first[RUNNING]->since);
	set_task_state(first[RUNNING]->id, PENDING); /* too old */
}



@ \section{Networking} 

To ease dealing with network sockets, we use the \ZMQ middleware
library~\cite{zeromq}. It transfers messages asynchronously between hosts, and
does not interpret them.

<<Header...>>=
#include <zmq.h>

@ Our server waits for requests from the clients and... serves them. Clients can
send two types of messages:
\begin{itemize}
\item The ``Hello'' message. It is a [[task_msg_t]] with a task id of
  $-1$. The server responds with another [[task_msg_t]] containing an actual task [[id]].

\item The ``result'' message. It encapsulates the [[task_msg_t]] describing
the task, along with the actual result, which is a [[result_t]]. The server
also responds with a new [[task_msg_t]].
\end{itemize}

This construction ensures that all messages received by the server begin with
a [[task_msg_t]] (only [[task_id]], [[hostname_length]] and [[hostname]] are
there in the ``hello'' message).

Both types are shared between the server and the client (note that the client
should only read [[id]] in it in the [[task_msg_t]]). The client should not
attempt to access [[start_time]] or [[completion_time]].

This has the drawback that two [[double]]s and the hostname are transmitted
several times for nothing, but it keeps the whole system quite simple.

<<server.h>>=
struct task_msg_t {
	int id;
	double start_time;
	double completion_time;
	int hostname_length;
	char hostname[];
};

struct result_t {
	int size;
	char payload[];
};

@ To communicate using \ZMQ, we need to setup a [[context]], and then
a[[socket]] can be created and bound to a network address. The user may choose
which IP adress and/or which network interface can be bound to the socket
using a command-line argument. We also need to allocate some memory to hold
received messages.

<<Initialize networking>>=
void *context = zmq_ctx_new();
void *socket = zmq_socket(context, ZMQ_REP);
if (zmq_bind(socket, server_address) != 0)
	errx(1, "zmq_bind : %s\n", zmq_strerror(errno));	


@ The main loop run indefinitely. The server must be manually stopped.

<<Main server loop>>=
printf("Server ready\n");
while (1) {
	struct task_msg_t *msg;
	int msg_size;
	<<Check for expired tasks; Mark them as [[PENDING]]>>
	<<Wait for incoming message; define [[msg]], [[msg_size]]>>
	if (msg->id >= 0) {
		<<Mark task [[msg->id]] as [[DONE]] and store [[msg]] in the journal>>
	}
	<<Send next [[PENDING]] task and mark it as [[RUNNING]]>>
	<<Release message memory>>    
	<<Display progress information>>
}


@ To receive a message, we must first create an (empty) \ZMQ \emph{message
  object}, call [[zmq_msg_recv]], then access the actual content of the message
with [[zmq_msg_data]].

<<Wait for incoming message...>>=
zmq_msg_t zmsg;
zmq_msg_init(&zmsg);
msg_size = zmq_msg_recv(&zmsg, socket, 0);
if (msg_size < 0)
	errx(1, "zmq_msg_recv %s", zmq_strerror(errno));
msg = zmq_msg_data(&zmsg);

@ Once message processing is over, we must release the memory used to store the
message (which is of arbitrary size).

<<Release...>>=
zmq_msg_close(&zmsg);

@ When a client requests work, we send the identifier of the next [[PENDING]]
task. If there are no more pending tasks, we send $-1$.

<<Send next [[PENDING]] task...>>=
int response_size = sizeof(struct task_msg_t) + msg->hostname_length;
struct task_msg_t *response = malloc(response_size);
response->start_time = wtime();
response->hostname_length = msg->hostname_length;
memcpy(response->hostname, msg->hostname, msg->hostname_length);
int i;
if (first[PENDING] == NULL) {
	i = -1;
} else {
	i = first[PENDING]->id;
	set_task_state(i, RUNNING);
}
response->id = i;
printf("Sending task %d to %s\n", response->id, response->hostname);
if (zmq_send(socket, response, response_size, 0) < 0)
	errx(1, "zmq_send : %s", zmq_strerror(errno));
free(response);
 

@ \section{Journal File}

The server stores information about completed tasks in a simple \emph{journal
file}. This file contains the identifiers of completed tasks and the results
of these tasks. If the server program is interrupted, then reading this file
allows to restart operations without the clients even noticing. In addition,
the journal file can be opened (for reading) by other programs running
concurrently with the server. This allows to exploit partial results of a
long-running computation.

The journal file may not exist; this is not an error. It will be created soon
enough. When parsing it, we hold the total CPU time spent in the computation.

To make things as easy as possible, the server (almost) just writes down all
the ``result'' messages it gets from the clients to this file. These messages
contain all the necessary metadata, except the task completion time, which is
set by the server. The journal file thus contains a sequence of
([[task_msg_t]], [[result_t]]) pairs, each of which is of variable length.


<<Global...>>=
FILE *journal_file;
double total_time;

<<Open journal file for reading; Mark completed tasks as [[DONE]]>>=
journal_file = fopen(journal_filename, "r");
if (journal_file != NULL) {
	while (1) {
		<<Read a [[task_msg_t]]; mark the task as [[DONE]]>>
		<<Skip over the hostname and read a [[result_t]]>>
		<<Skip over the result's payload>>
		total_time += task.completion_time - task.start_time;
	}
	fclose(journal_file);
	printf("found %d completed tasks in %s (%.0fs of computation)\n",
	    n_tasks[DONE], journal_filename, total_time);
}


<<Read a [[task_msg_t]]; mark the task as [[DONE]]>>=
struct task_msg_t task;
size_t x = fread(&task, sizeof(struct task_msg_t), 1, journal_file);
if (x != 1) {
	if (feof(journal_file))
		break;
	else 
		err(1, "reading journal file");
}
set_task_state(task.id, DONE);

<<Skip over the hostname and read a [[result_t]]>>=
fseek(journal_file, task.hostname_length, SEEK_CUR);
struct result_t result;
x = fread(&result, sizeof(struct result_t), 1, journal_file);
if (x != 1)
	err(1, "reading journal file (result)");

<<Skip over the result's payload>>=
fseek(journal_file, result.size, SEEK_CUR);


@ When the server receives a task completion notice from a client, it must store
the result of the task in the journal file. For this, the journal file must be
re-opened in ``append'' mode (this creates it if needs be).

<<Reopen the journal file for append>>=
journal_file = fopen(journal_filename, "a");
if (journal_file == NULL)
	err(1, "Impossible to open journal file %s for append\n", journal_filename);

@ The server sets the completion time of the task before saving it. The start
time of the task has already been set by the server in the [[task_msg_t]] sent
to the client and relayed back to the server.

<<Mark task [[msg->id]] as [[DONE]]...>>=
printf("collecting task %d\n", msg->id);
set_task_state(msg->id, DONE);
msg->completion_time = wtime();
size_t tmp = fwrite(msg, 1, msg_size, journal_file);
if (tmp != msg_size)
	err(1, "fwrite journal file");
if (fflush(journal_file))
	err(1, "fflush journal file");


@ \section{User interface}

And now the part we were all waiting for: verbosity.

<<Display progress...>>=
printf("task %d/%d, %d active, %.0f CPU.s, ", 
n_tasks[DONE], N, n_tasks[RUNNING], total_time);
   
@ \bibliographystyle{plain}
\bibliography{biblio}

\end{document}


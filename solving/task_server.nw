\documentclass{article}

\usepackage[a4paper]{geometry}
\usepackage{noweb}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{parskip}
\usepackage{xspace}
\usepackage{hyperref}

\usepackage{tikz}
\usetikzlibrary{arrows,automata}

\newcommand{\nanomsg}{\textsf{nanomsg}\xspace}

\begin{document}

\title{An Application-Agnostic Task Server}
\author{Charles Bouillaguet}

\maketitle

\section{Introduction} 

I only have access to computing environments where either I cannot choose when
my programs will run, or their running time is fairly limited, or they can be
interrupted at any moment. To run long, distributed computations in these
environnment I resorted to a classic client-server strategy: a long-running
server distributes \emph{tasks} to the clients and collects the \emph{results}
of these tasks once they are completed. Once a clients starts running, it
sends a \emph{task request} to the server. If the client is brutally
interrupted, then the task \emph{completion notice} will never be sent back to
the server. At some point, the server considers that the task is expired, and
it will send it to another client.

The server is light-weight and application-agnostic. Tasks are simply
integers, and their number is the only parameter of the server. The task
results are stored and not interpreted. I hope that this makes the server
reusable in a variety of contexts.

The server is (almost) stateless. It can be restarted at any time without
problem. It could have used the \textsf{HTTP} protocol, but instead it uses the
\nanomsg library to handle networking, in part because \nanomsg handles failures more
gracefully (and does a fraction of the job for us).

The global structure of the server program is classical.

<<*>>=
#define _XOPEN_SOURCE 500
<<Header files to include>>
<<Type definitions>>
<<Global variables>>
<<Functions>>
<<The main program>>


@ The main program is typical of a server.

<<The main program>>=
int main(int argc, char **argv)
{
	<<Set sensible default settings>>
	<<Process the command line>>
	<<Initialize $N$ [[PENDING]] tasks>>
	<<Open journal file for reading; Mark completed tasks as [[DONE]]>>
	<<Reopen the journal file for append>>
	<<Initialize networking>>
	<<Main server loop>>
}

@ Let us deal with the inevitable first: the inclusion of standard headers. The
\texttt{server.h} file contains type declaration shared between the server and
other programs.

<<Header files to include>>=
#include <stdlib.h>
#include <stdio.h>
#include <err.h>
#include <getopt.h>
#include <sys/time.h>
#include <string.h>
#include <assert.h>
#include "server.h"

@ Also inevitable, and rather boring, is the processing of command-line
options. The server takes four parameters:
\begin{itemize}
\item The number of tasks $N$ (mandatory).
\item The network address at which to listen (optional).
\item The name of the ``journal file'' to which task results are written (optional).
\item The duration after which tasks are in timeout and must be restarted (optional).
\end{itemize}

We use the standard POSIX [[getopt]] functions to deal with command-line options.

<<Global variables>>=
struct option longopts[5] = {
		{"N", required_argument, NULL, 'N'},
		{"journal-file", required_argument, NULL, 'j'},
		{"server-address", required_argument, NULL, 'a'},
		{"timeout", required_argument, NULL, 't'},
		{NULL, 0, NULL, 0}
};
int N = -1;
char *server_address = NULL;
char *journal_filename = NULL;
int task_timeout;

@ By default, the journal file is called \texttt{journal.log}, the server
address is \verb#tcp://*:5555# (which means ``all network interfaces on port
5555'') and tasks are rescheduled after 3600s.

<<Global variables>>=
static const char * DEFAULT_FILENAME = "journal.log";
static const char * DEFAULT_ADDRESS = "tcp://*:5555";
static const int DEFAULT_TIMEOUT = 3600;

<<Set sensible default settings>>=
server_address = strdup(DEFAULT_ADDRESS);
journal_filename = strdup(DEFAULT_FILENAME);
task_timeout = DEFAULT_TIMEOUT;

<<Process the command line>>=
char ch;
while ((ch = getopt_long(argc, argv, "", longopts, NULL)) != -1) {
	switch (ch) {
	case 'N':
		N = atoi(optarg);
		break;
	case 'a':
		server_address = optarg;
		break;
	case 'j':
		journal_filename = optarg;
		break;
	case 't':
		task_timeout = atoi(optarg);
		break;
	default:
		errx(1, "Unknown option\n");
	}
}
if (N < 0)
    errx(1, "missing argument --N");

@ We try to estimate the total time spent in performing tasks. For
this, we rely on the following function that returns the wall-clock
time (in seconds since the epoch) as a [[double]].

<<Functions>>=
double wtime()
{
	struct timeval ts;
	gettimeofday(&ts, NULL);
	return ts.tv_sec + (ts.tv_usec / 1e6);
}


@ \section{Tasks}

Tasks are simple integers in the range $[0; N[$. A task can be pending
execution, being run, or completed.

\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,node distance=4.5cm,
		      every state/.style={draw, outer sep=0pt,shape=rectangle},
		      accepting/.style={accepting by arrow, accepting where=below},
		      uplink/.style={transform canvas={yshift=1mm}},
		      downlink/.style={transform canvas={yshift=-1mm}}]

  \node[initial above,state]   (P)               {[[PENDING]]};
  \node[state]                 (R) [right of=P]  {[[RUNNING]]};
  \node[state,accepting] (D) [right of=R]  	 {[[DONE]]};

  \path (P) edge [uplink]   node[above] {task request} (R)
	(R) edge [downlink] node[below] {timeout}      (P)
	    edge            node[above] {task result}  (D);

  \draw (P) .. controls (3cm, -2cm) and (6cm, -2cm) .. node[below] {found in \texttt{journal.log}} (D);
\end{tikzpicture}
\end{center}


The tasks are arranged in three lists (one by task state) ; 
they move between lists at they are executed, completed
or when they expire. We thus use doubly-linked lists, with a special
``head'' node with an invalid task id. As such, lists are never empty. 

<<Type definitions>>=
enum state_t { PENDING, RUNNING, DONE };
struct task_t {
	int id;                        /* this is task number id */
	enum state_t state;            /* current state */
	double since;                  /* time of last state change */
	struct task_t *prev, *next;
};
 

@ The task lists are ordered: tasks are always added at the end of the
list. They can be removed arbitrarily. Access to the first/last task 
of the list is easy thanks to the head node.

<<Global variables>>=
int N;                   /* total number of tasks */
struct task_t *tasks;    /* all tasks */
int n_tasks[3];          /* number of tasks in each state */
struct task_t head[3];   /* head node of each list */

<<Functions>>=
void task_insert(struct task_t *t, enum state_t list)
{
	t->prev = head[list].prev;
	t->next = &head[list];
	t->prev->next = t;
	t->next->prev = t;
}

void task_delete(struct task_t *t)
{
	t->prev->next = t->next;
	t->next->prev = t->prev;
}


@ When the server starts, $N$ tasks are created, and they are all pending
execution. The [[tasks]] array holding all the tasks is dynamically allocated (it
allows direct access to the tasks by index), and the chained links are
set up. Note that the global variables [[n_tasks]] and [[head]] are
initialized to zero, as per the C language specification.

<<Initialize $N$ [[PENDING]] tasks>>=
<<Initialize the head nodes>>
tasks = malloc(N * sizeof(*tasks));
if (tasks == NULL)
	err(1, "failed to allocate all tasks");
for (int i = 0; i < N; i++) {
	tasks[i].id = i;
	tasks[i].state = PENDING;
}
for (int i = 0; i < N; i++)
	task_insert(&tasks[i], PENDING);
n_tasks[PENDING] = N;

@ On startup, the linked lists are empty, so the head nodes 
(with invalid task id) points to themselves. Only once the head nodes 
are ready can the insertion/deletion functions be invoked. 

<<Initialize the head nodes>>=
for (int class = 0; class < 3; class++) {
	head[class].id = -1;
	head[class].next = &head[class];
	head[class].prev = &head[class];
}

@ In addition to the above low-level functions, a few more administrative 
records have to be changed when a task changes state.

<<Functions>>=
void task_set_state(int i, enum state_t new_state)
{
	struct task_t *t = &tasks[i];
	n_tasks[t->state]--;
	task_delete(t);
	t->state = new_state;
	t->since = wtime();
	n_tasks[new_state]++;
	task_insert(t, new_state);
}

  
@ If a client is interrupted, the result of the task it was processing will
never be returned, and the task must be restarted at a later time. The server
detects this using a timeout mecanism. Tasks that have been attributed to a
client appear in the list of [[RUNNING]] tasks in increasing order of start
date. Checking for expired tasks amounts to check the first entries of this list.
This functions demonstrates the iteration over a circular doubly-linked list 
with special head node.

<<Functions>>=
void task_refresh()
{
	double threshold = wtime() - task_timeout;
	for (struct task_t *t = head[RUNNING].next; t->id != -1; t = t->next) {
		if (t->since > threshold)
			break;
		printf("Task %d timeout after %.0fs\n", t->id, wtime() - t->since);
		task_set_state(t->id, PENDING);
	}
}


@ \section{Networking} 

To ease dealing with network sockets, we use the \nanomsg middleware
library. It transfers messages asynchronously between hosts, and
does not interpret them.

<<Header files to include>>=
#include <nanomsg/nn.h>
#include <nanomsg/reqrep.h>

@ Our server waits for requests from the clients and... serves them. Clients can
send two types of messages:
\begin{itemize}
\item The ``Hello'' message. It is a [[task_msg_t]] with a task id of
  $-1$. The server responds with another [[task_msg_t]] containing an actual task [[id]].

\item The ``result'' message. It encapsulates the [[task_msg_t]] describing
the task, along with the actual result, which is a [[result_t]]. The server
also responds with a new [[task_msg_t]].
\end{itemize}

This construction ensures that all messages received by the server begin with
a [[task_msg_t]] (only [[task_id]], [[hostname_length]] and [[hostname]] are
meaningful in the ``hello'' message).

Both types are shared between the server and the client (note that the client
should only read [[id]] in it in the [[task_msg_t]]). The client should not
attempt to access [[start_time]] or [[completion_time]].

This has the drawback that two [[double]]s and the hostname are transmitted
several times for nothing, but it keeps the whole system quite simple.

If the server has no more tasks to dispatch, it sends a task id of $-1$, 
upon which clients exit.

<<server.h>>=
struct task_msg_t {
	int id;
	double start_time;
	double completion_time;
	int hostname_length;
	char hostname[];
};

struct result_t {
	int size;
	char payload[];
};

@ To communicate using \nanomsg, we need to setup a [[socket]], which is then 
bound or connected to a network address. The user may choose which IP adress 
and/or which network interface can be bound to the socket using a command-line
argument. We also need to allocate some memory to hold received messages.

<<Initialize networking>>=
int socket = nn_socket(AF_SP, NN_REP);
if (socket < 0)
	errx(1, "nn_socket : %s\n", nn_strerror(nn_errno()));
if (nn_bind(socket, server_address) < 0)
	errx(1, "nn_bind : %s\n", nn_strerror(nn_errno()));


@ The main loop run indefinitely. The server must be manually stopped.

<<Main server loop>>=
printf("Server ready on %s\n", server_address);
while (1) {
	<<Wait for incoming message; define [[msg]], [[msg_size]]>>
	task_refresh();
	if (msg->id >= 0) {
		<<Mark task [[msg->id]] as [[DONE]] and store [[msg]] in the journal>>
	}
	<<Send next [[PENDING]] task and mark it as [[RUNNING]]>>
	<<Release message memory>>
	<<Display progress information>>
}


@ We block on message reception (TODO: this may be a bad idea). The \nanomsg 
allocate enough space to hold the message (which makes us vulnerable to a DOS 
attack, but hey...).

<<Wait for incoming message; define [[msg]], [[msg_size]]>>=
struct task_msg_t *msg = NULL;
int msg_size = nn_recv(socket, &msg, NN_MSG, 0);
if (msg_size < 0)
	errx(1, "nn_recv : %s\n", nn_strerror(nn_errno()));


@ Once message processing is over, we must release the memory used to store the
message (which is of arbitrary size).

<<Release message memory>>=
nn_freemsg(msg);

@ When a client requests work, we send the identifier of the next [[PENDING]]
task. If there are no more pending tasks, we send $-1$.

<<Send next [[PENDING]] task and mark it as [[RUNNING]]>>=
int response_size = sizeof(struct task_msg_t) + msg->hostname_length;
struct task_msg_t *response = malloc(response_size);
response->start_time = wtime();
response->hostname_length = msg->hostname_length;
memcpy(response->hostname, msg->hostname, msg->hostname_length);
response->id = head[PENDING].next->id;
if (response->id >= 0)
	task_set_state(response->id, RUNNING);
printf("Sending task %d to %s\n", response->id, response->hostname);
if (nn_send(socket, response, response_size, 0) < 0)
	errx(1, "nn_send : %s\n", nn_strerror(nn_errno()));
free(response);
 

@ \section{Journal File}

The server stores information about completed tasks in a simple \emph{journal
file}. This file contains the identifiers of completed tasks and the results
of these tasks. If the server program is interrupted, then reading this file
allows to restart operations without the clients even noticing. In addition,
the journal file can be opened (for reading) by other programs running
concurrently with the server. This allows to exploit partial results of a
long-running computation.

The journal file may not exist; this is not an error. It will be created soon
enough. When parsing it, we hold the total CPU time spent in the computation.

To make things as easy as possible, the server (almost) just writes down all
the ``result'' messages it gets from the clients to this file. These messages
contain all the necessary metadata, except the task completion time, which is
set by the server. The journal file thus contains a sequence of
([[task_msg_t]], [[result_t]]) pairs, each of which is of variable length.


<<Global variables>>=
FILE *journal_file;
double total_time;

<<Open journal file for reading; Mark completed tasks as [[DONE]]>>=
journal_file = fopen(journal_filename, "r");
if (journal_file != NULL) {
	while (1) {
		<<Read a [[task_msg_t]]; mark the task as [[DONE]]>>
		<<Skip over the hostname and read a [[result_t]]>>
		<<Skip over the result's payload>>
		total_time += task.completion_time - task.start_time;
	}
	fclose(journal_file);
	printf("found %d completed tasks in %s (%.0fs of computation)\n",
	    n_tasks[DONE], journal_filename, total_time);
}


<<Read a [[task_msg_t]]; mark the task as [[DONE]]>>=
struct task_msg_t task;
size_t x = fread(&task, sizeof(struct task_msg_t), 1, journal_file);
if (x != 1) {
	if (feof(journal_file))
		break;
	else 
		err(1, "reading journal file");
}
task_set_state(task.id, DONE);


<<Skip over the hostname and read a [[result_t]]>>=
fseek(journal_file, task.hostname_length, SEEK_CUR);
struct result_t result;
x = fread(&result, sizeof(struct result_t), 1, journal_file);
if (x != 1)
	err(1, "reading journal file (result)");

<<Skip over the result's payload>>=
fseek(journal_file, result.size, SEEK_CUR);


@ When the server receives a task completion notice from a client, it must store
the result of the task in the journal file. For this, the journal file must be
re-opened in ``append'' mode (this creates it if needs be).

<<Reopen the journal file for append>>=
journal_file = fopen(journal_filename, "a");
if (journal_file == NULL)
	err(1, "Impossible to open journal file %s for append\n", journal_filename);

@ The server sets the completion time of the task before saving it. The start
time of the task has already been set by the server in the [[task_msg_t]] sent
to the client and relayed back to the server.

<<Mark task [[msg->id]] as [[DONE]] and store [[msg]] in the journal>>=
printf("collecting task %d\n", msg->id);
task_set_state(msg->id, DONE);
msg->completion_time = wtime();
size_t tmp = fwrite(msg, 1, msg_size, journal_file);
if (tmp != (size_t) msg_size)
	err(1, "fwrite journal file");
if (fflush(journal_file))
	err(1, "fflush journal file");


@ \section{User interface}

And now the part we were all waiting for: verbosity.

<<Display progress information>>=
printf("task %d/%d, %d active, %.0f CPU.s, ", 
	n_tasks[DONE], N, n_tasks[RUNNING], total_time);
   
@

\end{document}


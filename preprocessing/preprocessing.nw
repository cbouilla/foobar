\documentclass{book}
\usepackage{noweb}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{textcomp}
\usepackage{parskip}
\usepackage{geometry}
\usepackage{tikz}
\usepackage{xspace}
\usepackage{hyperref}

\def\noweb{{\tt noweb\/}}
\newcommand{\join}{\bowtie}

\newcommand{\ZMQ}{\textsf{$\varnothing$MQ}\xspace}
\newcommand{\NN}{\textsf{nanomsg}\xspace}
\newcommand{\MPI}{\textsf{MPI}\xspace}
\newcommand{\OMP}{\textsf{OpenMP}\xspace}

\begin{document}

\part{Preprocessing}

\chapter{Introduction}

The combination of the \texttt{FOOBAR}-modified Miner and the
\texttt{FOOBAR}-server yields \emph{preimage files}, containing (counter,
nonce) pairs. In this document, we call this a \textbf{preimage}. Each preimage
requires 12 bytes, and we expect to have 3 lists of $2^{31.7}$ entries each,
for a total storage space of 117Gbyte.

The preimage files must be checked (i.e. the corresponding hashes must have 32
zero bits). They must then be hashed, and 64 bits of each hash stored to disk.
This yields three hash lists, of $25.4$Gbyte each. These lists have to be
sorted and checked for duplicates. Thus in total, we expect to need $\approx
150$ Gbyte of storage.

Each preimage is associated to a 256-bit \textbf{full hash}, of which 33 at
least must be zero. More precisely, bits $[0:33]$ are zero. From this full hash, 
we extract a subset of 64 (uniformly distributed) bits (bits $[33:97]$) that we 
call the \textbf{hash}. Furthermore, we extract a $k$-bit \emph{partionning key} 
from the hash by taking bits $[97:97+k]$.

Each input list is partitionned according the the partitionning key into $2^k$ sublists. This serves two purposes
\begin{enumerate}
\item The sublists are smaller and thus more manageable.
\item All triplets in $A^{[i]} \times B^{[j]} \times C^{[i \oplus j]}$ are known to have a zero-sum on the bits of the partitionning key.
\end{enumerate}

With $k=10$, for instance, the sublists are $\approx 32$ Mbyte and there are 
$k^2 = $ 1 million subtasks to solve, which is probably enough.
Solving one such subtask should require less than 10 CPU-hours.

On the other hand, we do not strictly require that a ``task'' in the task 
distribution scheme maps exactly to sublists. We may want to keep sublists of RAM-size (say 1 Gbyte),
and split processing of sublists into smaller ``tasks''.

For various reasons, we enforce that the 64-bit hashes are unique in each sublist. For each 
sublist, we actually maintain a dictionnary $[[hash]] \rightarrow [[preimage]]$.

The miner generates $\approx 550$ preimages per second, which means roughly
550 Mbyte per day of fresh data. Ideally, we would like the total amount of
work required to integrate this much data to the dictionnary to be as low as
possible.

We use the following strategy :

\begin{enumerate}  
\item When a new preimage file is ready, split it into $2^k$ \textbf{sub-dictionnaries}
by partitionning according to the partitionning key. Potential duplicate preimages are 
now confined into a single sub-dictionnary.

\item Sort the sub-dictionnaries by hash. They must fit in RAM in order to do this easily.

\item For each partitionning key, perform a multiway merge on all sub-dictionnaries. 
Detect duplicate hashes and write down the hashes in order into a \textbf{hash file}.
\end{enumerate}

Concretely, a preimage file contains a sequence of [[struct preimage_t]]. A
split dictionnary contains a sequence of [[dict_t]]. These types are described 
in [[hasher.h]].

Filesystem-wise, we use the following conventions :
\begin{itemize}
\item Preimage files are named [[preimage/<kind>.<anything>]], where [[<kind>]] 
      is one of [[foo]], [[bar]] or [[foobar]].
\item Unsorted sub-dictionnaries extracted from [[preimage/<name>]] are named 
      [[dict/<key>/<name>.unsorted]], where [[<key>]] is the hex 
      representation of the partitionning key (preferably left-padded with zeroes).
\item The sorted version of [[dict/<key>/<name>]] is [[dict/<key>/<name>.sorted]].
\item The (merged) hashfiles are in [[hash/<kind>.<key>]]
\end{itemize}

All programs may assume that the directories already exist.

As stated above, the \emph{kind} of a preimage/dictionary file can be inferred from its name.

<<preprocessing.h>>=
#ifndef _PREPROCESSING_H
#define _PREPROCESSING_H
#include "../types.h"

enum kind_t { 
	FOO, 
	BAR, 
	FOOBAR
};

struct preimage_t {
	i64 counter;
	u32 nonce;
} __attribute__((packed));

struct dict_t {
	u64 hash;
	struct preimage_t preimage;
} __attribute__((packed));


enum kind_t file_get_kind(const char *filename);
u32 file_get_partition(const char *filename);
#endif

@ Obtaining parts of the filename is easy thanks to the POSIX functions [[basename]] 
and [[dirname]]... except that these modify their argument. We thus have to make a copy first and clean it up afterwards.

<<*>>=
#define _XOPEN_SOURCE  500  /* for strdup */
#include <string.h>
#include <strings.h>        /* strncasecmp */
#include <stdlib.h>
#include <libgen.h>
#include <err.h>
#include "preprocessing.h"

enum kind_t file_get_kind(const char *filename)
{
	enum kind_t out = -1;
	char *filename_ = strdup(filename);
	char *base = basename(filename_);
	if (strncasecmp(base, "foobar", 6) == 0)
		out = FOOBAR;
	else if (strncasecmp(base, "foo", 3) == 0)
		out = FOO;
	else if (strncasecmp(base, "bar", 3) == 0)
		out = BAR;
	else
		errx(1, "cannot determine kind of file %s", filename);
	free(filename_);
	return out;
}

u32 file_get_partition(const char *filename)
{
	char *filename_ = strdup(filename);
	char *dir = dirname(filename_);
	char *base = basename(dir);
	u32 out = strtol(base, NULL, 16);
	free(filename_);
	return out;
}

@ \section{Additional Preprocessing for Joux's Algorithm}

Lists $A$ and $B$ must not be sorted, so that it would make sense to randomly
permute each hash file.

For $C$, it seems reasonable to precompute the slices (thus enabling more
intensive precomputations in order to increase the size of slices). In
Addition to slice boundaries, we could store : $CM$ instead of $C$, as well as
$M$ and $M^{-1}$. Advantage: this drops the "compute-time" dependency on M4RI.

The $C$ hash file could be replaced by a sequence of :

<<preprocessing.h>>=
struct C_record_t {
	u64 M[64];
	u64 Minv[64];
	u32 n;
	u32 l;
	u64 CM[];
}  __attribute__((packed));

static inline u64 LEFT_MASK(u8 n)
{
	return ~((1ull << (64 - n)) - 1);
}


@ If the ``compute'' phase happens on the BGQ, then hash files should be byte-
swapped in advance.

\end{document}